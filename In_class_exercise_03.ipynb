{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In-class-exercise-03.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sravanivangala/sravani_INFO5731_Fall2021/blob/main/In_class_exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuS8YebGLmUn"
      },
      "source": [
        "## The third In-class-exercise (9/29/2021, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gWkBCbOLmUv"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmcIsebFLmUx"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ6QAL-KLmUy"
      },
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        " sentiment analysis is one of the best application of text mining technique in real world data. \n",
        " this approach is used to understand the sentiment of data from social media.\n",
        " This technique is also used for classifying the reviews from e-commerce websites.\n",
        "\n",
        "some of the features which are useful for the machine learning models to better understand the data are:\n",
        "word density : describes the density of numbers of words present in all the documents from the data\n",
        "bag-of-words: it is a representation of the data where each word is assigned as a vector from the data. \n",
        "              this feature assigns score for each word to review sentiment in sentiment analysis.\n",
        "entity feature extraction: this feature is used to identify key elements in the text and classify into predefined categories.\n",
        "feature matrix of tokens: this feature is a text representation where all the words in the document are converted into vectors\n",
        "              and the existence of the word is represented in the binary form.\n",
        "term frequency - inverse document frequency: this feature is a statistical measure that is calculated by multiplying \n",
        "              the number of times a word appears in the document by inverse document frequency of a word across all the documents.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlNMohD-LmU0"
      },
      "source": [
        "Question 2 (20 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWSwJMX-LmU0"
      },
      "source": [
        "!pip install spacy #installing spacy packages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8t74UDpXUfw"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETTbgNwNXdrz",
        "outputId": "05b24bee-6bb7-4328-b1dc-1e6472dbe391"
      },
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "#the entity types used to classify the data.\n",
        "entity_types = ['PERSON','NORP','FAC','ORG','GPE','LOC','PRODUCT','EVENT','WORK_OF_ART','LAW',\n",
        "                'LANGUAGE','DATE','TIME','PERCENT','MONEY','QUANTITY','ORDINAL','CARDINAL']\n",
        "#description of the entity codes discussed above\n",
        "entity_name = ['person','Nationality','Building','Institution','country','location','PRODUCT','EVENT','Title','LAW',\n",
        "                'LANGUAGE','DATE','TIME','PERCENT','MONEY','QUANTITY','ORDINAL','CARDINAL']\n",
        "#defining a function to classify the key elemnts in the data\n",
        "def entity_extraction(sentence):\n",
        "    entity_list = []\n",
        "    doc = nlp(sentence)\n",
        "    for ent in doc.ents: #returns all the entities in the document\n",
        "        entity_list.append([ent.text, ent.start_char, ent.end_char, ent.label_]) #appends the entity word, start and end of the word, label of the word\n",
        "    \n",
        "    return entity_list #returns the entity list\n",
        "\n",
        "sentence = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
        "\n",
        "entity_list = entity_extraction(sentence) #calling the function\n",
        "print(entity_list) #printing the output "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Apple', 0, 5, 'ORG'], ['U.K.', 27, 31, 'GPE'], ['$1 billion', 44, 54, 'MONEY']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cAMTIdMZXuy",
        "outputId": "39aa17a0-26f9-48be-df96-5b178de7ff05"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow = CountVectorizer(max_features=50, lowercase=True, ngram_range=(1,3),analyzer = \"word\") #assigning the attribute values for the count vectorizer function\n",
        "sentence = [\"Now this is a story all about how my life got flipped turned upside down\", \"You can't achieve your way out of childhood trauma.\" ]\n",
        "train_bow = bow.fit_transform(sentence) \n",
        "bow.get_feature_names() # getting feature names from bag of words of the document"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['about',\n",
              " 'about how',\n",
              " 'about how my',\n",
              " 'achieve',\n",
              " 'achieve your',\n",
              " 'achieve your way',\n",
              " 'all',\n",
              " 'all about',\n",
              " 'all about how',\n",
              " 'can',\n",
              " 'can achieve',\n",
              " 'can achieve your',\n",
              " 'childhood',\n",
              " 'childhood trauma',\n",
              " 'down',\n",
              " 'flipped turned',\n",
              " 'flipped turned upside',\n",
              " 'life got flipped',\n",
              " 'my',\n",
              " 'my life',\n",
              " 'my life got',\n",
              " 'now',\n",
              " 'now this',\n",
              " 'now this is',\n",
              " 'of',\n",
              " 'of childhood',\n",
              " 'of childhood trauma',\n",
              " 'out',\n",
              " 'out of',\n",
              " 'out of childhood',\n",
              " 'story',\n",
              " 'story all',\n",
              " 'story all about',\n",
              " 'this',\n",
              " 'this is',\n",
              " 'this is story',\n",
              " 'trauma',\n",
              " 'turned',\n",
              " 'turned upside',\n",
              " 'turned upside down',\n",
              " 'upside',\n",
              " 'upside down',\n",
              " 'way',\n",
              " 'way out',\n",
              " 'way out of',\n",
              " 'you',\n",
              " 'you can',\n",
              " 'you can achieve',\n",
              " 'your',\n",
              " 'your way']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdczP7urcE9l"
      },
      "source": [
        "import pandas\n",
        "trainDF = pandas.DataFrame()\n",
        "trainDF = sentence\n",
        "trainDF['char_count'] = trainDF[0].len() # calculating the character count of the document\n",
        "trainDF['word_count'] = trainDF[0].apply(lambda x: len(x.split())) #calculating the word count of the document\n",
        "trainDF['word_density'] = trainDF['char_count'] / (trainDF['word_count']+1) #calculating word density across the document\n",
        "trainDF[['text','word_density']].head() #prinitng the result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "5juh1H_znyS2",
        "outputId": "0af6c90c-b6e4-4960-ff95-a730e415adcd"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "vec = CountVectorizer(binary=True) #assigning the countvectorizer class functionality\n",
        "#data\n",
        "texts = [\n",
        "    \"blue car and blue window\",\n",
        "    \"black crow in the window\",\n",
        "    \"i see my reflection in the window\"\n",
        "]\n",
        "#fitting the data with the function\n",
        "vec.fit(texts)\n",
        "print([w for w in sorted(vec.vocabulary_.keys())]) #printing all the important key values\n",
        "\n",
        "pd.DataFrame(vec.transform(texts).toarray(), columns=sorted(vec.vocabulary_.keys())) #visualization the values existence in all docs"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and', 'black', 'blue', 'car', 'crow', 'in', 'my', 'reflection', 'see', 'the', 'window']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>black</th>\n",
              "      <th>blue</th>\n",
              "      <th>car</th>\n",
              "      <th>crow</th>\n",
              "      <th>in</th>\n",
              "      <th>my</th>\n",
              "      <th>reflection</th>\n",
              "      <th>see</th>\n",
              "      <th>the</th>\n",
              "      <th>window</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   and  black  blue  car  crow  in  my  reflection  see  the  window\n",
              "0    1      0     1    1     0   0   0           0    0    0       1\n",
              "1    0      1     0    0     1   1   0           0    0    1       1\n",
              "2    0      0     0    0     0   1   1           1    1    1       1"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "aM44kU-Iowyo",
        "outputId": "87a2e1bb-5c69-44c4-d2d1-9d7a973699d8"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec = TfidfVectorizer() #assigning the class functionality to calculate tf-idf values\n",
        "vec.fit(texts) #assigning the data \n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(vec.transform(texts).toarray(), columns=sorted(vec.vocabulary_.keys())) #visually representing the tf-idf values for all the elements in data"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>black</th>\n",
              "      <th>blue</th>\n",
              "      <th>car</th>\n",
              "      <th>crow</th>\n",
              "      <th>in</th>\n",
              "      <th>my</th>\n",
              "      <th>reflection</th>\n",
              "      <th>see</th>\n",
              "      <th>the</th>\n",
              "      <th>window</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.396875</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.793749</td>\n",
              "      <td>0.396875</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.534093</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.534093</td>\n",
              "      <td>0.406192</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.406192</td>\n",
              "      <td>0.315444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.358291</td>\n",
              "      <td>0.47111</td>\n",
              "      <td>0.47111</td>\n",
              "      <td>0.47111</td>\n",
              "      <td>0.358291</td>\n",
              "      <td>0.278245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        and     black      blue  ...      see       the    window\n",
              "0  0.396875  0.000000  0.793749  ...  0.00000  0.000000  0.234400\n",
              "1  0.000000  0.534093  0.000000  ...  0.00000  0.406192  0.315444\n",
              "2  0.000000  0.000000  0.000000  ...  0.47111  0.358291  0.278245\n",
              "\n",
              "[3 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2QxyeMULmU1"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\" Select the most important features you extracted above, rank the features based on their importance in the descending order. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_ed7DBQLmU2",
        "outputId": "9842e170-c8f2-49af-c440-58518be52079"
      },
      "source": [
        "# You code here (Please add comments in the code\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "  \n",
        "# Loading iris data\n",
        "iris_dataset = load_iris()\n",
        "  \n",
        "# Creating features and target\n",
        "X = iris_dataset.data\n",
        "y = iris_dataset.target\n",
        "  \n",
        "# Converting to categorical data by converting data to integers\n",
        "X = X.astype(int)\n",
        "  \n",
        "# Two features with highest chi-squared statistics are selected\n",
        "chi2_features = SelectKBest(chi2, k = 2)\n",
        "X_kbest_features = chi2_features.fit_transform(X, y)\n",
        "  \n",
        "# Reduced features\n",
        "print('Original feature number:', X.shape[1])\n",
        "print('Reduced feature number:', X_kbest_features.shape[1])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original feature number: 4\n",
            "Reduced feature number: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKOjW1NXIl-j"
      },
      "source": [
        "the features i have extracted in the previous question are all very useful in building the models. \n",
        "ranking the above features in order of their importance:\n",
        "1. TF-IDF values\n",
        "2. Feature matrix using binary encoding\n",
        "3. Entity feature\n",
        "4. Bag-of-words\n",
        "5. word density"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9upeVSFIhXp"
      },
      "source": [
        ""
      ]
    }
  ]
}